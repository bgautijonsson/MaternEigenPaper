% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[journal=,manuscript=]{achemso}
\usepackage[version=3]{mhchem}
\newcommand*\mycommand[1]{\texttt{\emph{#1}}}



\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}{}
\makeatother
\makeatletter
\makeatother
\makeatletter
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[borderline west={3pt}{0pt}{shadecolor}, sharp corners, interior hidden, breakable, frame hidden, enhanced, boxrule=0pt]}{\end{tcolorbox}}\fi
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Efficient Gaussian Copula Density Computation for Large-Scale Spatial Data: A Matérn-like GMRF Approach with Circulant and Folded Circulant Approximations},
  pdfauthor={Brynjólfur Gauti Guðrúnar Jónsson},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\author{Brynjólfur Gauti Guðrúnar Jónsson}
\affiliation{ University of Iceland,  }


\email{brynjolfur@hi.is}



\title[]{Efficient Gaussian Copula Density Computation for Large-Scale
Spatial Data: A Matérn-like GMRF Approach with Circulant and Folded
Circulant Approximations}
\makeatletter
\begin{document}
\maketitle
\begin{abstract}
This paper presents an algorithm for efficient computation of Gaussian
copula densities using Gaussian Markov Random Field (GMRF) precision
structures. We introduce a Matérn-like precision matrix with unit
marginal variance, leveraging a Kronecker sum structure that allows for
fast eigendecomposition. The method avoids explicit formation and
inversion of large precision matrices, making it particularly suitable
for high-dimensional spatial data. We propose two approximation methods:
circulant and folded circulant, which utilize the computational
efficiency of Fast Fourier Transforms (FFTs). The circulant
approximation treats the spatial field as if it were on a torus, where
opposite edges are connected. The folded circulant approximation,
however, uses a reflection boundary condition, effectively doubling the
size of the field by reflecting the data along each coordinate axis.
This approach potentially offers improved accuracy near field edges,
addressing a common limitation of periodic boundary conditions.
\end{abstract}


\section{Introduction}\label{introduction}

\subsection{Problem Formulation}\label{problem-formulation}

Consider a spatial field on a regular \(n \times n\) grid. Our objective
is to compute the Gaussian copula density efficiently for this field.
This computation involves:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Specifying a precision matrix \(\mathbf{Q}\) that represents the
  spatial dependence structure.
\item
  Ensuring the implied covariance matrix
  \(\mathbf{\Sigma} = \mathbf{Q}^{-1}\) has unit diagonal elements.
\item
  Computing the density for large spatial fields in a computationally
  efficient manner.
\end{enumerate}

\subsection{Review}\label{review}

Gaussian Markov Random Fields (GMRFs) and copulas are two powerful
statistical tools, each offering unique strengths in modeling complex
data structures. GMRFs excel in capturing spatial and temporal
dependencies, particularly in fields such as environmental science,
epidemiology, and image analysis. Their ability to represent local
dependencies through sparse precision matrices makes them
computationally attractive for high-dimensional problems. Copulas, on
the other hand, provide a flexible framework for modeling multivariate
dependencies, allowing separate specification of marginal distributions
and their joint behavior.

The Gaussian copula, in particular, has gained popularity due to its
interpretability and connection to the multivariate normal distribution.
However, combining GMRFs with copulas has historically been
computationally challenging, limiting their joint application to smaller
datasets or simpler models.

Let \(\mathbf{X} = (X_1, X_2, \ldots, X_n)\) be a multivariate random
vector with marginal distribution functions \(F_i\) for
\(i = 1, 2, \ldots, n\). The joint distribution function of
\(\mathbf{X}\) can be written as:

\[
F_{\mathbf{X}}(\mathbf{x}) = C(F_1(x_1), F_2(x_2), \ldots, F_n(x_n)),
\]

where \(C\) is the Gaussian copula defined by the GMRF precision matrix
\(\mathbf{Q}\). The Gaussian copula \(C\) is given by:

\[
C(u_1, u_2, \ldots, u_n) = \Phi_\mathbf{Q}(\Phi^{-1}(u_1), \Phi^{-1}(u_2), \ldots, \Phi^{-1}(u_n)),
\]

where \(\Phi_\mathbf{Q}\) is the joint cumulative distribution function
of a multivariate normal distribution with mean vector \(\mathbf{0}\)
and precision matrix \(\mathbf{Q}\), and \(\Phi^{-1}\) is the inverse of
the standard normal cumulative distribution function.

A critical requirement for the precision matrix \(\mathbf{Q}\) governing
the GMRF copula \(C\) is that \(\mathbf{\Sigma} = \mathbf{Q}^{-1}\)
should have a unit diagonal, i.e.~the marginal variance is equal to one
everywhere.. This ensures it operates on the same scale as the
transformed data, \(\Phi^{-1}(u_i)\). However, this can be challenging
as GMRFs are typically defined in terms of precision matrices that often
imply non-unit marginal variances.

This paper presents a novel algorithm that bridges the gap between GMRFs
and copulas, allowing for fast and efficient computation of Gaussian
copula densities using GMRF precision structures. Our method focuses on
creating a Matérn-like precision matrix \(\mathbf{Q}\) with unit
marginal variance and efficiently computing the multivariate Gaussian
copula density of \(\mathbf{Z} = \Phi^{-1}(\mathbf{u})\), where
\(u_i \sim \text{Uniform}(0, 1)\), \(i = 1, \dots, n\).

The key innovation lies in leveraging the special structure of the
precision matrix:

\[
\mathbf{Q} = \mathbf{Q}_1 \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{Q}_1,
\]

where \(\mathbf{Q}_1\) is the precision matrix of a standardized
one-dimensional AR(1) process and \(\otimes\) denotes the Kronecker
product. By employing efficient eigendecomposition techniques, our
method avoids explicit formation and inversion of the large precision
matrix \(\mathbf{Q}\), making it particularly suitable for
high-dimensional spatial data. In additions to the exact method, we
mention approximations to \(\mathbf{Q}\) using circuland and folded
circulant matrices.

\section{Methods}\label{methods}

\subsection{Gaussian Copula Density
Computation}\label{gaussian-copula-density-computation}

The Gaussian copula density for a random vector
\(\mathbf{U} = (U_1, ..., U_n)\) with \(U_i \sim \text{Uniform}(0,1)\)
is given by:

\[
c(\mathbf{u}) = |\mathbf{Q}|^{1/2} \exp\left(-\frac{1}{2}\mathbf{z}^T(\mathbf{Q} - \mathbf{I})\mathbf{z}\right)
\]

where \(\mathbf{z} = (z_1, ..., z_n)\) with \(z_i = \Phi^{-1}(u_i)\),
\(\mathbf{Q}\) is the precision matrix, and \(\mathbf{I}\) is the
identity matrix.

The log-density can be expressed as:

\[
\log c(\mathbf{u}) = \frac{1}{2}\log|\mathbf{Q}| - \frac{1}{2}\mathbf{z}^T\mathbf{Q}\mathbf{z} + \frac{1}{2}\mathbf{z}^T\mathbf{z}
\]

Our goal is to efficiently compute this log-density for large spatial
fields.

\subsection{Precision Matrix
Structure}\label{precision-matrix-structure}

We define the precision matrix \(\mathbf{Q}\) as:

\[
\mathbf{Q} = (\mathbf{Q}_1 \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{Q}_1)^{(\nu + 1)}, \quad \nu \in \{0, 1, 2\}
\]

where \(\mathbf{Q}_1\) is the precision matrix of a one-dimensional
AR(1) process:

\[
\mathbf{Q}_1 = \frac{1}{1-\rho^2}
\begin{bmatrix}
1 & -\rho & 0 & \cdots & 0 \\
-\rho & 1+\rho^2 & -\rho & \cdots & 0 \\
0 & -\rho & 1+\rho^2 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1
\end{bmatrix}
\]

The matrix, \(\mathbf Q\), is then scaled so that its inverse,
\(\mathbf \Sigma = \mathbf Q^{-1}\) has unit diagonals,
i.e.~\(\mathbf \Sigma_{ii} = 1\).

\subsection{Computation Process}\label{computation-process}

\subsubsection{\texorpdfstring{Step 1: Eigendecomposition of
\(\mathbf{Q}_1\)}{Step 1: Eigendecomposition of \textbackslash mathbf\{Q\}\_1}}\label{step-1-eigendecomposition-of-mathbfq_1}

We first compute the eigendecomposition of \(\mathbf{Q}_1\):

\[
\mathbf{Q}_1 = \mathbf{V}\mathbf{\Lambda}\mathbf{V}^T
\]

where \(\mathbf{V}\) is the matrix of eigenvectors and
\(\mathbf{\Lambda}\) is the diagonal matrix of eigenvalues. Then, the
eigendecomposition of \(\mathbf{Q}\) is:

\[
\mathbf{Q} = (\mathbf{V} \otimes \mathbf{V})(\mathbf{\Lambda} \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{\Lambda})^{(\nu + 1)}(\mathbf{V} \otimes \mathbf{V})^T.
\]

This means that the eigenvectors of \(\mathbf{Q}\) are
\(\mathbf{v}_j \otimes \mathbf{v}_i\) and the corresponding eigenvalues
are \(\lambda_i + \lambda_j\).

\subsubsection{Step 2: Computation of Marginal Standard
Deviations}\label{step-2-computation-of-marginal-standard-deviations}

Using the eigendecomposition of \(\mathbf{Q}_1\), we compute the
marginal standard deviations and store them in a vector
\(\mathbf{\sigma}\), i.e.~\(\sigma_i = \sqrt{\Sigma_{ii}}\):

\[
\mathbf{\sigma} = \sqrt{\sum_{i,j} \frac{(\mathbf{v}_j \otimes \mathbf{v}_i)^2}{(\lambda_i + \lambda_j)^\nu}}
\]

where \(\mathbf{v}_i\) are the eigenvectors and \(\lambda_i\) are the
eigenvalues of \(\mathbf{Q}_1\). Thus, \(\sigma\) will be a vector of
length \(n^2\).

\subsubsection{Step 3: Scaling the
Eigendecomposition}\label{step-3-scaling-the-eigendecomposition}

We scale the eigendecomposition of \(\mathbf{Q}\) using the marginal
standard deviations:

\[
\begin{aligned}
\mathbf{\widetilde  Q} &= \mathbf{D}\mathbf{Q}\mathbf{D} \\
&= \mathbf{D}(\mathbf{V} \otimes \mathbf{V})(\mathbf{\Lambda} \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{\Lambda})^\nu(\mathbf{V} \otimes \mathbf{V})^T\mathbf{D} \\
&= (\mathbf{\widetilde V} \otimes \mathbf{\widetilde V})(\mathbf{\widetilde\Lambda} \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{\widetilde \Lambda})(\mathbf{\widetilde V} \otimes \mathbf{\widetilde V})^T
\end{aligned}
\]

where \(\mathbf{D}\) is a diagonal matrix with \(D_{ii} = \sigma_i\).

\subsubsection{Step 4: Efficient Computation of
Log-Density}\label{step-4-efficient-computation-of-log-density}

Using this scaled eigendecomposition, we efficiently compute:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Log-determinant:
  \(\log|\mathbf{\widetilde Q}| = \sum_{i,j} \log(\widetilde\lambda_i + \widetilde\lambda_j)\)
\item
  Quadratic form:
  \(\mathbf{z}^T\mathbf{\widetilde Q}\mathbf{z} = \sum_{i,j} (\widetilde\lambda_i + \widetilde\lambda_j) y_{ij}^2\),
  where
  \(y_{ij} = (\mathbf{\widetilde v}_j \otimes \mathbf{\widetilde v}_i)^T\mathbf{z}\)
\end{enumerate}

This approach allows for efficient computation of the Gaussian copula
density without explicitly forming the full \(n^2 \times n^2\) precision
matrix \(\mathbf{Q}\) or its inverse \(\mathbf{\Sigma}\).

\subsection{Circulant and Folded Circulant
Approximations}\label{circulant-and-folded-circulant-approximations}

While the eigendecomposition method provides an exact solution, it can
be computationally expensive for very large spatial fields. To address
this, we introduce circulant and folded circulant approximations that
offer potential computational advantages.

\subsubsection{Circulant Matrices}\label{circulant-matrices}

A circulant matrix \(C\) is a special kind of matrix where each row is a
cyclic shift of the row above it. It can be fully specified by its first
row or column, called the base \(c\):

\[
C = \begin{pmatrix}
c_0 & c_1 & c_2 & \cdots & c_{n-1} \\
c_{n-1} & c_0 & c_1 & \cdots & c_{n-2} \\
c_{n-2} & c_{n-1} & c_0 & \cdots & c_{n-3} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
c_1 & c_2 & c_3 & \cdots & c_0
\end{pmatrix} = (c_{j-i \mod n})
\]

The base vector \(c\) completely determines the circulant matrix and
plays a crucial role in efficient computations. In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The eigenvalues of \(C\) are given by the Discrete Fourier Transform
  (DFT) of \(c\): \[
  \lambda_k = \sum_{j=0}^{n-1} c_j e^{-2\pi i jk/n}, \quad k = 0, 1, ..., n-1
  \]
\item
  Matrix-vector multiplication can be performed using the FFT: \[
  Cv = \frac1n\text{DFT}(\text{DFT}(c) \odot \text{IDFT}(v))
  \]
\item
  The determinant of \(C\) is the product of its eigenvalues: \[
  \det(C) = \prod_{k=0}^{n-1} \lambda_k
  \]
\item
  When \(C\) is non singular, then the inverse is circulant and thus
  determined by its base:
\end{enumerate}

\[
\frac1n \text{IDFT}(\text{DFT}(c)^{-1}).
\]

These properties allow for much faster computations than for general
matrices.

\subsubsection{Block Circulant Matrices}\label{block-circulant-matrices}

For two-dimensional spatial fields, we use block circulant matrices with
circulant blocks (BCCB). An \(Nn \times Nn\) matrix C is block circulant
if it has the form:

\[
C = \begin{pmatrix}
C_0 & C_1 & C_2 & \cdots & C_{N-1} \\
C_{N-1} & C_0 & C_1 & \cdots & C_{N-2} \\
C_{N-2} & C_{N-1} & C_0 & \cdots & C_{N-3} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
C_1 & C_2 & C_3 & \cdots & C_0
\end{pmatrix} = (C_{j-i \mod N})
\]

where each \(C_i\) is itself a circulant \(n \times n\) matrix.

For a BCCB matrix, we define a base matrix \(\mathbf c\), which is an
\(n \times N\) matrix where each column is the base vector of the
corresponding circulant block. This base matrix \(\mathbf c\) completely
determines the BCCB matrix and is central to efficient computations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The eigenvalues of \(C\) are given by the 2D DFT of \(\mathbf c\): \[
  \Lambda_{k,l} = \sum_{i=0}^{n-1} \sum_{j=0}^{N-1} c_{ij} e^{-2\pi i (ki/n + lj/N)}, \quad k = 0, \dots, n-1, l = 0, \dots, N-1
  \]
\item
  Matrix-vector multiplication can be performed using the 2D FFT: \[
  Cv = \text{IDFT2}(\text{DFT2}(c) \odot \text{DFT2}(v))
  \]
\item
  The determinant of \(C\) is the product of its eigenvalues: \[
  \det(C) = \prod_{k=0}^{n-1} \prod_{l=0}^{N-1} \Lambda_{k,l}
  \]
\end{enumerate}

\subsubsection{Computational Advantages}\label{computational-advantages}

The circulant structure allows for efficient computation using the Fast
Fourier Transform (FFT):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Matrix-vector multiplication: For a circulant matrix C with base c and
  a vector v \[
  Cv = \sqrt{n} \text{DFT}(\text{DFT}(c) \odot \text{IDFT}(v)),
  \]
\item
  Matrix inverse: The base of \(C^{-1}\) is given by \[
  \frac{1}{n} \text{IDFT}(\text{DFT}(c)^{-1}).
  \]
\end{enumerate}

\subsubsection{Approximations for Q1}\label{approximations-for-q1}

Let \(Q_1\) be the precision matrix of a one-dimensional AR(1) process
with n observations. The exact form of \(Q_1\) is:

\[
\mathbf{Q}_1 = \frac{1}{1-\rho^2}
\begin{bmatrix}
1 & -\rho & 0 & \cdots & 0 \\
-\rho & 1+\rho^2 & -\rho & \cdots & 0 \\
0 & -\rho & 1+\rho^2 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1
\end{bmatrix}
\]

\paragraph{Circulant Approximation}\label{circulant-approximation}

The circulant approximation to \(Q_1\), denoted as
\(\mathbf{Q}_1^{(circ)}\), is:

\[
\mathbf{Q}_1^{(circ)} = \frac{1}{1-\rho^2}
\begin{bmatrix}
1+\rho^2 & -\rho & 0 & \cdots & 0 & -\rho \\
-\rho & 1+\rho^2 & -\rho & \cdots & 0 & 0 \\
0 & -\rho & 1+\rho^2 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
-\rho & 0 & 0 & \cdots & -\rho & 1+\rho^2
\end{bmatrix}
\]

This approximation treats the first and last observations as neighbors,
effectively wrapping the data around a circle.

\paragraph{Folded Circulant
Approximation}\label{folded-circulant-approximation}

The folded circulant approximation, \(\mathbf{Q}_1^{(fold)}\), is based
on a reflected version of the data. We double the data by reflecting it,
giving us the data \(x_1,  \dots, x_n, x_n, \dots, x_1\). We then model
this doubled data with a \(2n \times 2n\) circulant matrix. If written
out as an \(n \times n\) matrix, it takes the form:

\[
\mathbf{Q}_1^{(fold)} = \frac{1}{1-\rho^2}
\begin{bmatrix}
1-\rho+\rho^2 & -\rho & 0 & \cdots & 0 & 0 \\
-\rho & 1+\rho^2 & -\rho & \cdots & 0 & 0 \\
0 & -\rho & 1+\rho^2 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & -\rho & 1-\rho+\rho^2
\end{bmatrix}
\]

This approximation modifies the first and last diagonal elements to
account for the reflection of the data. As \(x_1\) now is the first and
last data point, then we avoid the circular dependence from the regular
circulant approximation.

\subsubsection{Extension to the Full Q
Matrix}\label{extension-to-the-full-q-matrix}

For a two-dimensional spatial field on an \(n \times n\) grid, we
construct the full precision matrix Q using a Kronecker sum:

\[
\mathbf{Q} = (\mathbf{Q}_1 \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{Q}_1)^{(\nu + 1)}
\]

where \(\otimes\) denotes the Kronecker product, I is the \(n \times n\)
identity matrix, and \(\nu\) is a smoothness parameter.

When we approximate \(Q_1\) with a circulant matrix, this Kronecker sum
results in a block-circulant matrix with circulant blocks (BCCB). To see
this, let's consider the case where \(\nu = 0\) for simplicity:

\[
\mathbf{Q} = \mathbf{Q}_1 \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{Q}_1
\]

Now, let \(Q_1\) be approximated by a circulant matrix C with base
vector \(c = [c_, c_1, ..., c_{n-1}]\). Then:

\[
\mathbf{Q}_1 \approx \mathbf{C} = 
\begin{pmatrix}
c_0 & c_1 & \cdots & c_{n-1} \\
c_{n-1} & c_0 & \cdots & c_{n-2} \\
\vdots & \vdots & \ddots & \vdots \\
c_1 & c_2 & \cdots & c_0
\end{pmatrix}
\]

The Kronecker product \(C \otimes I\) results in a block matrix where
each block is a scalar multiple of I:

\[
\mathbf{C} \otimes \mathbf{I} = 
\begin{pmatrix}
c_0\mathbf{I} & c_1\mathbf{I} & \cdots & c_{n-1}\mathbf{I} \\
c_{n-1}\mathbf{I} & c_0\mathbf{I} & \cdots & c_{n-2}\mathbf{I} \\
\vdots & \vdots & \ddots & \vdots \\
c_1\mathbf{I} & c_2\mathbf{I} & \cdots & c_0\mathbf{I}
\end{pmatrix}
\]

Similarly, I ⊗ C results in a block matrix where each block is a copy of
C:

\[
\mathbf{I} \otimes \mathbf{C} = 
\begin{pmatrix}
\mathbf{C} & \mathbf{0} & \cdots & \mathbf{0} \\
\mathbf{0} & \mathbf{C} & \cdots & \mathbf{0} \\
\vdots & \vdots & \ddots & \vdots \\
\mathbf{0} & \mathbf{0} & \cdots & \mathbf{C}
\end{pmatrix}
\]

The sum of these two matrices is a block-circulant matrix with circulant
blocks:

\[
\mathbf{Q} \approx \mathbf{C} \otimes \mathbf{I} + \mathbf{I} \otimes \mathbf{C} = 
\begin{pmatrix}
\mathbf{B}_0 & \mathbf{B}_1 & \cdots & \mathbf{B}_{n-1} \\
\mathbf{B}_{n-1} & \mathbf{B}_0 & \cdots & \mathbf{B}_{n-2} \\
\vdots & \vdots & \ddots & \vdots \\
\mathbf{B}_1 & \mathbf{B}_2 & \cdots & \mathbf{B}_0
\end{pmatrix}
\]

where each \(\mathbf{B_i}\) is a circulant matrix. Specifically,
\(\mathbf{B_0} = c_0I + C\), and for \(i \neq 0\),
\(\mathbf{B_i} = c_iI\).

This BCCB structure allows us to use 2D FFT for efficient computations.
The base matrix \(\mathbf c\) for this BCCB structure is:

\[
\mathbf{c} = \begin{bmatrix}
2+2\rho^2 & -\rho & 0 & \cdots  & -\rho \\
-\rho & 0 & 0 & \cdots  & 0 \\
0 & 0 & 0 & \cdots  & 0 \\
\vdots & \vdots & \vdots & \ddots &  \vdots \\
-\rho & 0 & 0 & \cdots  & 0
\end{bmatrix}
\]

This base matrix \(c\) captures the structure of the precision matrix
\(Q\) and allows for efficient computation of eigenvalues using the 2D
Fast Fourier Transform (FFT), enabling rapid calculation of the
log-determinant and quadratic forms needed for the Gaussian copula
density.

\subsection{Computation with Circulant
Approximation}\label{computation-with-circulant-approximation}

When using the circulant approximation, we leverage the efficient
computation properties of block circulant matrices with circulant blocks
(BCCB). This approach significantly reduces the computational
complexity, especially for large spatial fields. Here's the step-by-step
process:

\subsubsection{1. Construct the Base
Matrix}\label{construct-the-base-matrix}

First, we construct the base matrix c for our BCCB approximation of Q.
For an n × n grid, c is an n × n matrix:

\[
\mathbf{c} = \begin{bmatrix}
2+2\rho^2 & -\rho & 0 & \cdots & 0 & -\rho \\
-\rho & 0 & 0 & \cdots & 0 & 0 \\
0 & 0 & 0 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
-\rho & 0 & 0 & \cdots & 0 & 0
\end{bmatrix}
\]

This base matrix encapsulates the structure of our Matérn-like precision
matrix.

\subsubsection{2. Compute Initial
Eigenvalues}\label{compute-initial-eigenvalues}

We compute the initial eigenvalues of Q using the 2D Fast Fourier
Transform (FFT) of c:

\[
\boldsymbol{\Lambda} = \text{FFT2}(\mathbf{c})^{\nu+1}
\]

where ν is the smoothness parameter.

\subsubsection{3. Compute Marginal Variance and Rescale
Eigenvalues}\label{compute-marginal-variance-and-rescale-eigenvalues}

An important property of Block Circulant with Circulant Blocks (BCCB)
matrices is that the inverse of a BCCB matrix is also a BCCB matrix with
a constant diagonal. We use this to efficiently compute the marginal
variance and rescale the eigenvalues:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Compute the element-wise inverse of \(\boldsymbol{\Lambda}\):
  \(\mathbf{\Lambda^{inv}} = 1 / \boldsymbol{\Lambda}\)
\item
  Compute the base of \(Q^{-1}\) using inverse 2D FFT:
  \(\mathbf{c_{inv}} = \text{IFFT2}(\mathbf{{\Lambda^{inv}}})\)
\item
  The marginal variance is given by the first element of
  \(\mathbf{c^{inv}}\): \(\sigma^2 = \mathbf{c^{inv}}_{(0,0)}\)
\item
  Rescale the eigenvalues:
  \(\boldsymbol{\widetilde \Lambda} = \sigma^2 \boldsymbol{\Lambda}\)
\end{enumerate}

This process ensures that the resulting precision matrix will have unit
marginal variances, as required for the Gaussian copula.

\subsubsection{4. Compute
Log-Determinant}\label{compute-log-determinant}

The log-determinant of the scaled \(\mathbf{\widetilde Q}\) can be
efficiently calculated as the sum of the logarithms of the scaled
eigenvalues:

\[
\log|\mathbf{Q}| = \sum_{i,j} \log(\widetilde \Lambda_{ij})
\]

\subsubsection{5. Compute Quadratic Form}\label{compute-quadratic-form}

To compute the quadratic form \(\mathbf{z}^T\mathbf{Q}\mathbf{z}\), we
use the following steps:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Compute the 2D FFT of z:
  \(\mathbf{\hat{z}} = \text{FFT2}(\mathbf{z})\)
\item
  Multiply element-wise with the scaled eigenvalues:
  \(\mathbf{\hat{y}} = \boldsymbol{\widetilde \Lambda} \odot \mathbf{\hat{z}}\)
\item
  Compute the inverse 2D FFT:
  \(\mathbf{y} = \text{IFFT2}(\mathbf{\hat{y}})\)
\item
  Compute the dot product:
  \(\mathbf{z}^T\mathbf{Q}\mathbf{z} = \mathbf{z}^T\mathbf{y}\)
\end{enumerate}

\subsubsection{6. Compute the
Log-Density}\label{compute-the-log-density}

Finally, we can compute the log-density of the Gaussian copula:

\[
\log c(\mathbf{u}) = \frac{1}{2}\log|\mathbf{Q}| - \frac{1}{2}\mathbf{z}^T\mathbf{Q}\mathbf{z} + \frac{1}{2}\mathbf{z}^T\mathbf{z}
\]

where \(\mathbf{z} = \Phi^{-1}(\mathbf{u})\).

\subsection{Computation with Folded Circulant
Approximation}\label{computation-with-folded-circulant-approximation}

The folded circulant approximation offers an alternative approach that
can provide better accuracy near the edges of the spatial field. This
method is based on the idea of reflecting the data along each coordinate
axis, effectively doubling the size of the field. Other than that, the
algorithmic implementation is the same except that the circulant
approximation matrices to \(Q_1\) are now \(2n \times 2n\).

First, we reflect the data along each coordinate axis. For a 2D spatial
field represented by an \(n \times n\) matrix, the reflected data takes
the form:

\[
\begin{bmatrix}
x_{11} & \cdots & x_{1n} & x_{1n} & \cdots & x_{11} \\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
x_{n1} & \cdots & x_{nn} & x_{nn} & \cdots & x_{n1} \\
x_{n1} & \cdots & x_{nn} & x_{nn} & \cdots & x_{n1} \\
\vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\
x_{11} & \cdots & x_{1n} & x_{1n} & \cdots & x_{11}
\end{bmatrix}
\]

This reflection creates a \(2n \times 2n\) matrix. The matrix is then
stacked in lexicographic order before entering into the quadratic forms.

\section{Results}\label{results}

\subsection{Computational Efficiency}\label{computational-efficiency}

Table 1 presents the results of a benchmark comparing the time it takes
to evaluate the gaussian copula density described above. For each grid
size, we report the computation time for the exact method and the two
approximations, along with the speed-up factor relative to the exact
method. Each calculation was performed twenty times and the median times
are shown in the table.

\begin{longtable}[]{@{}llllll@{}}
\caption{Table 1. Benchmarking how long it takes to evaluate the density
of a Mátern(\(\nu\))-like field with correlation parameter \(\rho\),
scaled to have unit marginal variance.}\tabularnewline
\toprule\noalign{}
Q\_size & Exact & Circulant & & Folded & \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Q\_size & Exact & Circulant & & Folded & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& Time & Time & Speed-Up & Time & Speed-Up \\
100x100 & 194.69μs & 33.89μs & 5.75x & 44.77μs & 4.35x \\
400x400 & 309.61μs & 37.45μs & 8.27x & 122.78μs & 2.52x \\
900x900 & 790.30μs & 85.65μs & 9.23x & 155.47μs & 5.08x \\
1600x1600 & 1.96ms & 98.71μs & 19.86x & 243.64μs & 8.05x \\
3600x3600 & 8.66ms & 151.70μs & 57.1x & 484.07μs & 17.89x \\
10000x10000 & 71.81ms & 343.07μs & 209.31x & 1.36ms & 52.76x \\
19600x19600 & 246.40ms & 667.58μs & 369.09x & 2.89ms & 85.32x \\
40000x40000 & 997.32ms & 1.44ms & 694.46x & 7.69ms & 129.69x \\
\end{longtable}

The results demonstrate significant computational gains from both
approximation methods, with the efficiency advantage increasing for
larger grid sizes. Key observations include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Scalability}: Both approximation methods show superior
  scalability compared to the exact method. As the grid size increases,
  the speed-up factor generally increases, indicating that the
  approximations become increasingly advantageous for larger spatial
  fields.
\item
  \textbf{Circulant Approximation Performance}: The circulant
  approximation consistently outperforms the folded circulant
  approximation in terms of speed. For the largest grid size
  (40000x40000), it achieves a remarkable 694.46x speed-up over the
  exact method.
\item
  \textbf{Folded Circulant Approximation}: While not as fast as the
  circulant approximation, the folded circulant method still offers
  substantial speed improvements, reaching a 129.69x speed-up for the
  40000x40000 grid.
\item
  \textbf{Trade-off Considerations}: The choice between the circulant
  and folded circulant approximations may depend on the specific
  requirements of the application. While the circulant approximation is
  faster, the folded circulant method may offer better accuracy,
  particularly near the edges of the spatial field.
\end{enumerate}

These results underscore the practical value of our approximation
methods, especially for large-scale spatial analyses where computational
efficiency is crucial. The substantial speed-ups achieved, particularly
for larger grids, demonstrate the potential of these methods to enable
the analysis of much larger spatial datasets than previously feasible
with exact methods.

\section{Appendix}\label{appendix}

\subsection{Cholesky Methods}\label{cholesky-methods}

Standard methods of evaluating multivariate normal densities using the
Cholesky decomposition were implemented to compare with the new methods
for benchmarking.

\subsubsection{Unscaled Precision
Matrix}\label{unscaled-precision-matrix}

\paragraph{Precision Matrix
Construction}\label{precision-matrix-construction}

We start by constructing the precision matrix \(Q\) for a 2D Matérn
field on a grid of size \(d_x \times d_y\):

\[
Q = Q_1 \otimes I_{d_y} + I_{d_x} \otimes Q_2 
\]

where \(\otimes\) denotes the Kronecker product, \(Q_1\) and \(Q_2\) are
1D precision matrices for the x and y dimensions respectively (typically
AR(1)-like structures), and \(I_{d_x}\) and \(I_{d_y}\) are identity
matrices of appropriate sizes.

\paragraph{Cholesky Decomposition}\label{cholesky-decomposition}

We compute the Cholesky decomposition of \(Q\): \[
Q = LL^T
\]

where L is a lower triangular matrix.

\paragraph{Density Computation}\label{density-computation}

For a Matérn field with smoothness parameter \(\nu\), we need to work
with \(Q^{\nu+1}\). The key insight is that we can efficiently compute
log-determinant, \(\log|Q^{\nu+1}|\), and the quadratic form,
\(x^T Q^{\nu+1} x\), without explicitly forming \(Q^{\nu+1}\). We make
use of the facts that

\[
\log|Q^{\nu+1}| = (\nu+1)\log|Q| = 2(\nu+1)\sum_{i}\log(L_{ii}),
\]

and

\[
\begin{aligned}
x^T Q x &= x^T L L^T x = ||L^T x||_2^2 \\
x^T Q^2 x &=  x^T L L^T L L^T x = ||LL^T x||_2^2 \\
x^T Q^3 x &=  x^T L L^T L L^T L L^T x = ||L^TLL^T x||_2^2,
\end{aligned}
\]

to efficiently calculate the quadratic form using only the Cholesky
factor of \(Q\) instead of forming the matrix \(Q^\nu\).

\paragraph{Algorithm}\label{algorithm}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct \(Q = Q_1 \otimes I_{d_y} + I_{d_x} \otimes Q_2\)
\item
  Compute Cholesky decomposition \(Q = LL^T\)
\item
  Compute log-determinant:
  \(\log|Q^{\nu+1}| = 2(\nu+1)\sum_{i}\log(L_{ii})\)
\item
  For each observation \(x\):

  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    Initialize \(y = x\)
  \item
    For \(j\) from 0 to \(\nu\):

    \begin{itemize}
    \tightlist
    \item
      If \(j\) is even: \(y = L^T y\)
    \item
      If \(j\) is odd: \(y = L y\)
    \end{itemize}
  \item
    Compute quadratic form \(q = y^Ty\)
  \end{enumerate}
\item
  Compute log-density:
  \(\log p(x) = -\frac{1}{2}(d\log(2\pi) + \log|Q^{\nu+1}| + q)\)
\end{enumerate}

\subsubsection{Scaled Precision Matrix}\label{scaled-precision-matrix}

\paragraph{Precision Matrix
Construction}\label{precision-matrix-construction-1}

We start by constructing the precision matrix \(Q\) for a 2D Matérn
field on a grid of size \(d_x \times d_y\):

\[
Q = Q_1 \otimes I_{d_y} + I_{d_x} \otimes Q_2 
\]

where \(\otimes\) denotes the Kronecker product, \(Q_1\) and \(Q_2\) are
1D precision matrices for the x and y dimensions respectively (typically
AR(1)-like structures), and \(I_{d_x}\) and \(I_{d_y}\) are identity
matrices of appropriate sizes. We will then have to work with the matrix
\(Q^{\nu + 1}\).

To ensure unit marginal variances, we need to scale this precision
matrix. Let \(D\) be a diagonal matrix where
\(D_{ii} = \sqrt{\Sigma_{ii}}\), and \(\Sigma = (Q^{\nu+1})^{-1}\). The
scaled precision matrix is then: \[
\tilde{Q} = DQ^{\nu+1}D
\]

\paragraph{Cholesky Decomposition}\label{cholesky-decomposition-1}

We compute the Cholesky decomposition of \(Q\): \[
Q = LL^T
\]

where L is a lower triangular matrix.

\paragraph{Efficient Computation of Scaling Matrix
D}\label{efficient-computation-of-scaling-matrix-d}

Computing \(D\) directly would require inverting \(Q^{\nu + 1}\), which
is computationally expensive. Instead, we can efficiently compute \(D\)
using the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Compute the Cholesky decomposition of the original \(Q = LL^T\)
\item
  Compute \(R = L^{-1}\), so that \(S = Q^{-1} = R^TR\).
\item
  We then calculate the entries in \(D\) using the following steps:

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    For \(\nu = 0\),
    \(D_{ii} = \sqrt{\Sigma_{ii}} = \sqrt{\sum_j (R_{ji})^2}\), the
    column-wise norm of \(R\).
  \item
    For \(\nu = 1\), we use the column-wise norm of \(R^TR\)
  \item
    For \(\nu = 2\), we use the column-wise norm of \(RR^TR\)
  \end{enumerate}
\end{enumerate}

This gives us the matrix D without having to explicitly invert the
matrix Q.

\paragraph{Log determinant}\label{log-determinant}

The log determinant of the scaled precision matrix
\(\tilde{Q} = DQ^{\nu+1}D\) can be computed efficiently using the
following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First, note that
  \(\log|\tilde{Q}| = \log|DQ^{\nu+1}D| = 2\log|D| + \log|Q^{\nu+1}|\)
\item
  We can compute \(\log|D|\) directly from the diagonal elements of D,
  i.e.~\(\log|D| = \sum_i \log(D_{ii})\)
\item
  For \(\log|Q^{\nu+1}|\), we can use the properties of the Cholesky
  decomposition:
  \(\log|Q^{\nu+1}| = (\nu+1)\log|Q| = (\nu+1)\log|LL^T| = 2(\nu+1)\sum_i \log(L_{ii})\)
\item
  Combining these, we get
  \(\log|\tilde{Q}| = 2\sum_i \log(D_{ii}) + 2(\nu+1)\sum_i \log(L_{ii})\)
\end{enumerate}

This allows us to compute the log determinant efficiently without
explicitly forming \(Q^{\nu+1}\) or its inverse.

\paragraph{Quadratic Form}\label{quadratic-form}

For the quadratic form \(z^T\tilde{Q}z\), where \(z = \Phi^{-1}(u)\), we
can use the following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  First, note that
  \(z^T\tilde{Q}z = z^TDQ^{\nu+1}Dz = (Dz)^TQ^{\nu+1}(Dz)\)
\item
  Let \(y = Dz\). We can compute this element-wise as
  \(y_i = D_{ii}z_i\)
\item
  Now we need to compute \(y^TQ^{\nu+1}y\). We can do this efficiently
  using the Cholesky factor L:

  \begin{enumerate}
  \def\labelenumii{\roman{enumii}.}
  \tightlist
  \item
    For \(\nu = 0\): \(y^TQy = ||L^Ty||_2^2\)
  \item
    For \(\nu = 1\): \(y^TQ^2y = ||LL^Ty||_2^2\)
  \item
    For \(\nu = 2\): \(y^TQ^3y = ||L^TLL^Ty||_2^2\)
  \end{enumerate}
\item
  In general, we can compute this as follows:

  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    Initialize \(y = Dz\)
  \item
    For j from 0 to \(\nu\):

    \begin{itemize}
    \tightlist
    \item
      If j is even: \(y = L^Ty\)
    \item
      If j is odd: \(y = Ly\)
    \end{itemize}
  \item
    Compute quadratic form \(q = y^Ty\)
  \end{enumerate}
\end{enumerate}

This approach allows us to compute the quadratic form efficiently
without explicitly forming \(Q^{\nu+1}\).

\paragraph{Algorithm}\label{algorithm-1}

Putting it all together, here's the algorithm for computing the
log-density of the Gaussian copula using the scaled precision matrix:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Construct \(Q = Q_1 \otimes I_{d_y} + I_{d_x} \otimes Q_2\)
\item
  Compute Cholesky decomposition \(Q = LL^T\)
\item
  Compute \(R = L^{-1}\) and use it to compute D as described earlier
\item
  Compute log-determinant:
  \(\log|\tilde{Q}| = 2\sum_i \log(D_{ii}) + 2(\nu+1)\sum_i \log(L_{ii})\)
\item
  For each observation \(z = \Phi^{-1}(u)\):

  \begin{enumerate}
  \def\labelenumii{\roman{enumii})}
  \tightlist
  \item
    Compute \(y = Dz\)
  \item
    For j from 0 to \(\nu\):

    \begin{itemize}
    \tightlist
    \item
      If j is even: \(y = L^Ty\)
    \item
      If j is odd: \(y = Ly\)
    \end{itemize}
  \item
    Compute quadratic form \(q = y^Ty\)
  \end{enumerate}
\item
  Compute log-density:
  \(\log c(u) = -\frac{1}{2}(d\log(2\pi) + \log|\tilde{Q}| + q - z^Tz)\)
\end{enumerate}

This algorithm computes the Gaussian copula density using the scaled
precision matrix, avoiding explicit formation or inversion of
\(\tilde Q = DQ^{\nu + 1}D\).




\end{document}
